{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Activation, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "# kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "from subprocess import check_output\n",
    "#list the files in the input directory\n",
    "#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "#print(check_output([\"pwd\",\"\"]).decode(\"utf8\")) # returns /kaggle/working\n",
    "#classes = check_output([\"ls\", \"../input/train\"]).decode(\"utf8\") # returns 12 directories\n",
    "#print((classes))\n",
    "def classes_to_int(label):\n",
    "    # label = classes.index(dir)\n",
    "    label = label.strip()\n",
    "    if label == \"Black-grass\":  return 0\n",
    "    if label == \"Charlock\":  return 1\n",
    "    if label == \"Cleavers\":  return 2\n",
    "    if label == \"Common Chickweed\":  return 3\n",
    "    if label == \"Common wheat\":  return 4\n",
    "    if label == \"Fat Hen\":  return 5\n",
    "    if label == \"Loose Silky-bent\": return 6\n",
    "    if label == \"Maize\":  return 7\n",
    "    if label == \"Scentless Mayweed\": return 8\n",
    "    if label == \"Shepherds Purse\": return 9\n",
    "    if label == \"Small-flowered Cranesbill\": return 10\n",
    "    if label == \"Sugar beet\": return 11\n",
    "    print(\"Invalid Label\", label) \n",
    "    return 12\n",
    "\n",
    "def int_to_classes(i):\n",
    "    if i == 0: return \"Black-grass\"\n",
    "    elif i == 1: return \"Charlock\"\n",
    "    elif i == 2: return \"Cleavers\"\n",
    "    elif i == 3: return \"Common Chickweed\"\n",
    "    elif i == 4: return \"Common wheat\"\n",
    "    elif i == 5: return \"Fat Hen\"\n",
    "    elif i == 6: return \"Loose Silky-bent\"\n",
    "    elif i == 7: return \"Maize\"\n",
    "    elif i == 8: return \"Scentless Mayweed\"\n",
    "    elif i == 9: return \"Shepherds Purse\"\n",
    "    elif i == 10: return \"Small-flowered Cranesbill\"\n",
    "    elif i == 11: return \"Sugar beet\"\n",
    "    print(\"Invalid class \", i)\n",
    "    return \"Invalid Class\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 12\n",
    "# we need images of same size so we convert them into the size\n",
    "WIDTH = 128\n",
    "HEIGHT = 128\n",
    "DEPTH = 3\n",
    "inputShape = (WIDTH, HEIGHT, DEPTH)\n",
    "# initialize number of epochs to train for, initial learning rate and batch size\n",
    "EPOCHS = 15\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "\n",
    "def readTrainData(trainDir):\n",
    "    data = []\n",
    "    labels = []\n",
    "    # loop over the input images\n",
    "    dirs = os.listdir(trainDir) \n",
    "    for dir in dirs:\n",
    "        absDirPath = os.path.join(os.path.sep,trainDir, dir)\n",
    "        images = os.listdir(absDirPath)\n",
    "        for imageFileName in images:\n",
    "            # load the image, pre-process it, and store it in the data list\n",
    "            imageFullPath = os.path.join(trainDir, dir, imageFileName)\n",
    "            #print(imageFullPath)\n",
    "            img = load_img(imageFullPath)\n",
    "            arr = img_to_array(img)  # Numpy array with shape (233,233,3)\n",
    "            arr = cv2.resize(arr, (HEIGHT,WIDTH)) #Numpy array with shape (HEIGHT, WIDTH,3)\n",
    "            #print(arr.shape) \n",
    "            data.append(arr)\n",
    "            label = classes_to_int(dir)\n",
    "            labels.append(label)\n",
    "    return data, labels\n",
    "\n",
    "def createModel():\n",
    "    model = Sequential()\n",
    "    # first set of CONV => RELU => POOL layers\n",
    "    # The CONV  layer will learn 20 convolution filters, each of which are 5×5.\n",
    "    model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=inputShape))\n",
    "    # We then apply a ReLU activation function followed by 2×2 max-pooling in both \n",
    "    # the x and y direction with a stride of two. \n",
    "    #To visualize this operation, consider a sliding window that “slides” across \n",
    "    #the activation volume, taking the max operation over each region, while taking \n",
    "    #a step of two pixels in both the horizontal and vertical direction.\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    # second set of CONV => RELU => POOL layers\n",
    "    #This time we are learning 50 convolutional filters rather than the 20 convolutional\n",
    "    #filters as in the previous layer set. It’s common to see the number of CONV \n",
    "    #filters learned increase the deeper we go in the network architecture.\n",
    "    model.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    # first (and only) set of FC => RELU layers\n",
    "    # Flattening out the volume into a set of fully-connected layers\n",
    "    # Take the output of the preceding MaxPooling2D layer and flatten it into a single vector.\n",
    "    # This operation allows us to apply our dense/fully-connected layers.\n",
    "    # Fully-connected layer contains 500 nodes which is passed through another \n",
    "    # nonlinear ReLU activation.\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    # softmax classifier\n",
    "    # Another fully-connected layer, but this one is special — the number of nodes is equal \n",
    "    # to the number of classes  (i.e., the classes we want to recognize).\n",
    "    # This Dense layer is then fed into our softmax classifier\n",
    "    # which will yield the probability for each class.\n",
    "    model.add(Dense(output_dim=12))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    # returns our fully constructed deep learning + Keras image classifier \n",
    "    opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "    # use binary_crossentropy if there are two classes\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images...\n",
      "Parttition data into 75:25...\n",
      "Generating images...\n",
      "compiling model...\n",
      "WARNING:tensorflow:From C:\\Users\\Biswajeet Mohanty\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "training network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Biswajeet Mohanty\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:66: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=12)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Biswajeet Mohanty\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/15\n",
      "111/111 [==============================] - 137s 1s/step - loss: 2.3925 - acc: 0.1661 - val_loss: 2.1442 - val_acc: 0.2382\n",
      "Epoch 2/15\n",
      "111/111 [==============================] - 130s 1s/step - loss: 1.8387 - acc: 0.3501 - val_loss: 1.6068 - val_acc: 0.4242\n",
      "Epoch 3/15\n",
      "111/111 [==============================] - 131s 1s/step - loss: 1.5376 - acc: 0.4671 - val_loss: 1.2286 - val_acc: 0.5556\n",
      "Epoch 4/15\n",
      "111/111 [==============================] - 131s 1s/step - loss: 1.2592 - acc: 0.5608 - val_loss: 1.2136 - val_acc: 0.5598\n",
      "Epoch 5/15\n",
      "111/111 [==============================] - 132s 1s/step - loss: 1.1065 - acc: 0.6208 - val_loss: 1.0114 - val_acc: 0.6549\n",
      "Epoch 6/15\n",
      "111/111 [==============================] - 131s 1s/step - loss: 1.0466 - acc: 0.6412 - val_loss: 1.0046 - val_acc: 0.6347\n",
      "Epoch 7/15\n",
      "111/111 [==============================] - 131s 1s/step - loss: 1.0331 - acc: 0.6480 - val_loss: 0.9147 - val_acc: 0.6785\n",
      "Epoch 8/15\n",
      "111/111 [==============================] - 130s 1s/step - loss: 0.9397 - acc: 0.6791 - val_loss: 0.8032 - val_acc: 0.7155\n",
      "Epoch 9/15\n",
      "111/111 [==============================] - 131s 1s/step - loss: 0.9131 - acc: 0.6837 - val_loss: 0.7837 - val_acc: 0.7357\n",
      "Epoch 10/15\n",
      "111/111 [==============================] - 131s 1s/step - loss: 0.8772 - acc: 0.6999 - val_loss: 0.7319 - val_acc: 0.7449\n",
      "Epoch 11/15\n",
      "111/111 [==============================] - 130s 1s/step - loss: 0.7786 - acc: 0.7327 - val_loss: 0.6890 - val_acc: 0.7542\n",
      "Epoch 12/15\n",
      "111/111 [==============================] - 130s 1s/step - loss: 0.7666 - acc: 0.7425 - val_loss: 0.6617 - val_acc: 0.7727\n",
      "Epoch 13/15\n",
      "111/111 [==============================] - 130s 1s/step - loss: 0.7074 - acc: 0.7641 - val_loss: 0.6361 - val_acc: 0.7736\n",
      "Epoch 14/15\n",
      "111/111 [==============================] - 130s 1s/step - loss: 0.6871 - acc: 0.7679 - val_loss: 0.6712 - val_acc: 0.7660\n",
      "Epoch 15/15\n",
      "111/111 [==============================] - 130s 1s/step - loss: 0.7051 - acc: 0.7518 - val_loss: 0.5873 - val_acc: 0.8013\n",
      "Saving model to disk\n"
     ]
    }
   ],
   "source": [
    "random.seed(10)\n",
    "allLabels =  os.listdir(\"D:\\\\input\\\\train\")  # list of subdirectories and files\n",
    "print(\"Loading images...\")\n",
    "sys.stdout.flush()\n",
    "X, Y = readTrainData(\"D:\\\\input\\\\train\")\n",
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "X = np.array(X, dtype=\"float\") / 255.0\n",
    "Y = np.array(Y)\n",
    "# convert the labels from integers to vectors\n",
    "Y =  to_categorical(Y, num_classes=12)\n",
    "\n",
    "print(\"Parttition data into 75:25...\")\n",
    "sys.stdout.flush()\n",
    "# partition the data into training and testing splits using 75% training and 25% for validation\n",
    "(trainX, valX, trainY, valY) = train_test_split(X,Y,test_size=0.25, random_state=10)\n",
    "\n",
    "#construct the image generator for data augmentation\n",
    "print(\"Generating images...\")\n",
    "sys.stdout.flush()\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1, \\\n",
    "    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\\\n",
    "    horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "# initialize the model\n",
    "print(\"compiling model...\")\n",
    "sys.stdout.flush()\n",
    "model = createModel()\n",
    "# train the network\n",
    "print(\"training network...\")\n",
    "sys.stdout.flush()\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS), \\\n",
    "    validation_data=(valX, valY), \\\n",
    "    steps_per_epoch=len(trainX) // BS, epochs=EPOCHS, verbose=1)\n",
    "\n",
    "# save the model to disk\n",
    "print(\"Saving model to disk\")\n",
    "sys.stdout.flush()\n",
    "model.save('./rf_reg.pkl')\n",
    "\n",
    "# set the matplotlib backend so figures can be saved in the background\n",
    "# plot the training loss and accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating plots...\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as pp\n",
    "print(\"Generating plots...\")\n",
    "sys.stdout.flush()\n",
    "matplotlib.use(\"Agg\")\n",
    "pp.style.use(\"ggplot\")\n",
    "pp.figure()\n",
    "N = EPOCHS\n",
    "pp.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "pp.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "pp.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "pp.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "pp.title(\"Training Loss and Accuracy on  crop classification\")\n",
    "pp.xlabel(\"Epoch #\")\n",
    "pp.ylabel(\"Loss/Accuracy\")\n",
    "pp.legend(loc=\"lower left\")\n",
    "pp.savefig(\"plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 291ms/step\n",
      "Writing complete\n"
     ]
    }
   ],
   "source": [
    "def readTestData(testDir):\n",
    "    data = []\n",
    "    filenames = []\n",
    "    # loop over the input images\n",
    "    images = os.listdir(testDir)\n",
    "    for imageFileName in images:\n",
    "        # load the image, pre-process it, and store it in the data list\n",
    "        imageFullPath = os.path.join(testDir, imageFileName)\n",
    "        #print(imageFullPath)\n",
    "        img = load_img(imageFullPath)\n",
    "        arr = img_to_array(img)  # Numpy array with shape (...,..,3)\n",
    "        arr = cv2.resize(arr, (HEIGHT,WIDTH)) \n",
    "        data.append(arr)\n",
    "        filenames.append(imageFileName)\n",
    "    return data, filenames\n",
    "\n",
    "# read test data and find its classification\n",
    "testX, filenames = readTestData('C:\\\\xampp\\\\htdocs\\\\concept\\\\uploads')\n",
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "testX = np.array(testX, dtype=\"float\") / 255.0\n",
    "\n",
    "from keras.models import load_model\n",
    "mymodel = load_model('./rf_reg.pkl')\n",
    "yFit = mymodel.predict(testX, batch_size=10, verbose=1)\n",
    "\n",
    "#print(type(yFit)) # numpy.ndarray\n",
    "#print(type(filenames)) # list\n",
    "\n",
    "import csv  \n",
    "with open('output.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['file', 'species']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for index, file in enumerate(filenames):\n",
    "        classesProbs = yFit[index]\n",
    "        maxIdx = 0\n",
    "        maxProb = 0;\n",
    "        for idx in range(0,11):\n",
    "            if(classesProbs[idx] > maxProb):\n",
    "                maxIdx = idx\n",
    "                maxProb = classesProbs[idx]\n",
    "        writer.writerow({'file': file, 'species': int_to_classes(maxIdx)})\n",
    "print(\"Writing complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00ef713a8.png ---This image is of --->  Common Chickweed\n"
     ]
    }
   ],
   "source": [
    "print((file) + \" ---This image is of --->  \" + int_to_classes(maxIdx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
